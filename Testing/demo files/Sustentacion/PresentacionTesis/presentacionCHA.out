\BOOKMARK [2][]{Outline0.1}{Motivaci\363n y definici\363n del problema}{}% 1
\BOOKMARK [2][]{Outline0.2}{Soluci\363n propuesta}{}% 2
\BOOKMARK [2][]{Outline0.3}{Aprendizaje por refuerzo}{}% 3
\BOOKMARK [3][]{Outline0.3.1.4}{RL un agente}{Outline0.3}% 4
\BOOKMARK [3][]{Outline0.3.2.5}{RL multiagente}{Outline0.3}% 5
\BOOKMARK [2][]{Outline0.4}{Coordinaci\363n en MARL}{}% 6
\BOOKMARK [2][]{Outline0.5}{Enfoques para establecer coordinaci\363n}{}% 7
\BOOKMARK [2][]{Outline0.6}{Q-Learning y grafos de coordinaci\363n}{}% 8
\BOOKMARK [3][]{Outline0.6.1.13}{VE}{Outline0.6}% 9
\BOOKMARK [2][]{Outline0.7}{Q-Learning y best response}{}% 10
\BOOKMARK [3][]{Outline0.7.1.15}{Pasos}{Outline0.7}% 11
\BOOKMARK [2][]{Outline0.8}{Espacio de estados y acciones}{}% 12
\BOOKMARK [2][]{Outline0.9}{Funci\363n de recompensa}{}% 13
\BOOKMARK [2][]{Outline0.10}{Marco de prueba}{}% 14
\BOOKMARK [2][]{Outline0.11}{Resultados}{}% 15
\BOOKMARK [3][]{Outline0.11.1.22}{Curva de aprendizaje}{Outline0.11}% 16
\BOOKMARK [3][]{Outline0.11.2.23}{Indicadores de desempe\361o}{Outline0.11}% 17
\BOOKMARK [3][]{Outline0.11.3.24}{Indicadores de desempe\361o del sistema}{Outline0.11}% 18
\BOOKMARK [3][]{Outline0.11.4.25}{Indicadores de desempe\361o por agente}{Outline0.11}% 19
\BOOKMARK [3][]{Outline0.11.5.26}{Tiempo de viaje}{Outline0.11}% 20
\BOOKMARK [2][]{Outline0.12}{Conclusiones}{}% 21
\BOOKMARK [2][]{Outline0.13}{Trabajo futuro}{}% 22
\BOOKMARK [2][]{Outline0.14}{Videos}{}% 23
\BOOKMARK [2][]{Outline0.15}{Preguntas}{}% 24
